{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0dd998473dbd4892f34807bf19aeea9c12a70ba84b1a5d02d168816cec7a7d398",
   "display_name": "Python 3.8.5 64-bit ('mlflow-xray': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "dd998473dbd4892f34807bf19aeea9c12a70ba84b1a5d02d168816cec7a7d398"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import git\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mlflow_info\n",
    "\n",
    "import keras \n",
    "from keras.utils import np_utils\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%reload_ext mlflow_info"
   ]
  },
  {
   "source": [
    "## creating a ssh-tunnel to server in the background"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" creating a ssh-tunnel to server in the background \"\"\"\n",
    "command = 'ssh -N -L 5000:localhost:5432 artinmajdi@data7-db1.cyverse.org &'\n",
    "ssh_session = subprocess.Popen('exec ' + command, stdout=subprocess.PIPE, shell=True)"
   ]
  },
  {
   "source": [
    "## Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], num_pixels)).astype('float32')\n",
    "x_test  = x_test.reshape( (x_test.shape[0],  num_pixels)).astype('float32')\n",
    "\n",
    "x_train = x_train[1:5000] / 255\n",
    "x_test  = x_test / 255\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train[1:5000])\n",
    "y_test  = np_utils.to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "source": [
    "## Architecture"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.keras.autolog()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "source": [
    "## setting up mlflow"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" MLflow settings: \n",
    "    The style we should use when running mlflow ui\n",
    "        Postgres server: server = f'{dialect_driver}://{username}:{password}@{ip}/{database_name}' \n",
    "        Local:           server = \"file:/Users/artinmac/Documents/Research/Data7/mlflow/mlrun_store\" \"\"\"\n",
    "\n",
    "postgres_connection_type = { 'direct':    ('5432', 'data7-db1.cyverse.org'),\n",
    "                            'ssh-tunnel': ('5000', 'localhost') }\n",
    "\n",
    "port, host = postgres_connection_type['ssh-tunnel']\n",
    "\n",
    "\n",
    "\"\"\" Setting up the artifact server \"\"\"\n",
    "username = 'username'\n",
    "password = 'password'\n",
    "database_name  = 'resbaz2021'\n",
    "dialect_driver = 'postgresql'\n",
    "\n",
    "server = '{dialect_driver}://{username}:{password}@{host}:{port}/{database_name}'\n",
    "\n",
    "Artifacts = {\n",
    "    'local':      'file:/{path_to_artifact_store}',\n",
    "    'hpc':        'sftp://{user}:{password}@filexfer.hpc.arizona.edu:{path_to_artifact_store}',\n",
    "    'atmosphere': 'sftp://{user}:{password}@{ip_address}:{path_to_artifact_store}',\n",
    "    'cyverse':    'file:/{path_to_artifact_store}',\n",
    "    'data7_db1':  'sftp://{user}:{password}@{ip_address}:{path_to_artifact_store}'}\n",
    "\n",
    "artifact = Artifacts['data7_db1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "server, artifact = mlflow_info.load()\n",
    "\n",
    "\"\"\" setting the trackinng uri \"\"\"\n",
    "mlflow.set_tracking_uri(server)\n",
    "\n",
    "\"\"\" Creating/Setting the experiment\n",
    "    Line below should be commented if the experiment is already created\n",
    "    If kept commented during the first run of a new experiment, the set_experiment \n",
    "    will automatically create the new experiment with local artifact storage \"\"\"\n",
    "\n",
    "experiment_name = 'exp_mnist'\n",
    "mlflow.create_experiment(name=experiment_name, artifact_location=artifact)\n",
    "mlflow.set_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "source": [
    "## model training and optimization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.7043 - binary_accuracy: 0.9609 - val_loss: 0.3222 - val_binary_accuracy: 0.9812\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.2640 - binary_accuracy: 0.9846 - val_loss: 0.2530 - val_binary_accuracy: 0.9845\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.1676 - binary_accuracy: 0.9904 - val_loss: 0.2326 - val_binary_accuracy: 0.9859\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.1278 - binary_accuracy: 0.9927 - val_loss: 0.2276 - val_binary_accuracy: 0.9865\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0991 - binary_accuracy: 0.9943 - val_loss: 0.2382 - val_binary_accuracy: 0.9861\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2382 - binary_accuracy: 0.9861\n",
      "Accuracy: 0.9860796928405762\n",
      "Loss:  0.23816725611686707\n",
      "git commit hash 58524e1b77bdba60e3cd5a37e53b636331e81194\n",
      "process completed\n",
      "CPU times: user 13.3 s, sys: 2.03 s, total: 15.4 s\n",
      "Wall time: 9.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Starting the MLflow \n",
    "run = mlflow.start_run()\n",
    "mlflow.set_tag(f'mlflow.note.content',f'run_id: {run.info.run_id}')\n",
    "\n",
    "\n",
    "# model compiling\n",
    "learning_rate = 0.001\n",
    "model.compile( optimizer = keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "               loss      = keras.losses.categorical_crossentropy,\n",
    "               metrics   = [keras.metrics.binary_accuracy] )\n",
    "\n",
    "# model optimization\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=100, validation_data=(x_test, y_test))\n",
    "\n",
    "# Model evaluation\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Accuracy:', test_acc) \n",
    "print('Loss: '   , test_loss)\n",
    "\n",
    "prediction = model.predict(x_test)\n",
    "predicted_classes = np.argmax(prediction, axis=1)\n",
    "\n",
    "# Saving MLflow parameters & metrics\n",
    "mlflow.log_param(\"epochs\",          history.params['epochs'])\n",
    "mlflow.log_param(\"steps_per_epoch\", history.params['steps'])\n",
    "mlflow.log_metric(\"accuracy\",       test_acc)\n",
    "mlflow.log_metric(\"test_loss\",      test_loss)\n",
    "\n",
    "# saving git commit hash\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "git_commit_hash = repo.head.object.hexsha\n",
    "print('git commit hash', git_commit_hash)\n",
    "mlflow.set_tag('mlflow.source.git.commit', git_commit_hash)\n",
    "\n",
    "\n",
    "# ending mlflow session\n",
    "mlflow.end_run()\n",
    "\n",
    "print('process completed')"
   ]
  },
  {
   "source": [
    "## finding the optimum learning rate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2393 - binary_accuracy: 0.9867\n",
      "\n",
      "Accuracy: 0.9867396354675293\n",
      "Loss:  0.23927639424800873 \n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.6071 - binary_accuracy: 0.9781\n",
      "\n",
      "Accuracy: 0.9780802726745605\n",
      "Loss:  0.6071300506591797 \n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.3075 - binary_accuracy: 0.9460\n",
      "\n",
      "Accuracy: 0.9459601640701294\n",
      "Loss:  1.3074679374694824 \n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.2563 - binary_accuracy: 0.9023\n",
      "\n",
      "Accuracy: 0.9023482203483582\n",
      "Loss:  2.256269693374634 \n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.3029 - binary_accuracy: 0.9000\n",
      "\n",
      "Accuracy: 0.900047242641449\n",
      "Loss:  2.302863359451294 \n",
      "\n",
      "100%|██████████| 5/5 [00:44<00:00,  8.88s/it]\n",
      "process completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Starting the MLflow \n",
    "parent_run = mlflow.start_run(run_name='learning rate')\n",
    "\n",
    "for learning_rate in tqdm(np.linspace(start=0.01,stop=0.1,num=5)):\n",
    "    \n",
    "    learning_rate = np.floor(learning_rate*1000)/1000\n",
    "\n",
    "    with mlflow.start_run(run_name=f'LR {learning_rate}', nested=True) as child_run:\n",
    "        mlflow.set_tag(f'mlflow.note.content',f'run_id: {child_run.info.run_id}')\n",
    "\n",
    "        # model compiling\n",
    "        model.compile( optimizer = keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                        loss     = keras.losses.categorical_crossentropy,\n",
    "                        metrics  = [keras.metrics.binary_accuracy] )\n",
    "\n",
    "        # model optimization\n",
    "        history = model.fit(x_train, y_train, epochs=5, batch_size=100, validation_data=(x_test, y_test),verbose=0)\n",
    "\n",
    "        # Model evaluation\n",
    "        test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "        print('\\nAccuracy:', test_acc) \n",
    "        print('Loss: '   , test_loss,'\\n')\n",
    "\n",
    "        prediction = model.predict(x_test)\n",
    "        predicted_classes = np.argmax(prediction, axis=1)\n",
    "\n",
    "        # Saving MLflow parameters & metrics\n",
    "        mlflow.log_param(\"epochs\",          history.params['epochs'])\n",
    "        mlflow.log_param(\"steps_per_epoch\", history.params['steps'])\n",
    "        mlflow.log_metric(\"accuracy\",       test_acc)\n",
    "        mlflow.log_metric(\"test_loss\",      test_loss)\n",
    "\n",
    "        # saving git commit hash\n",
    "        repo = git.Repo(search_parent_directories=True)\n",
    "        git_commit_hash = repo.head.object.hexsha\n",
    "        mlflow.set_tag('mlflow.source.git.commit', git_commit_hash)\n",
    "\n",
    "# ending mlflow session\n",
    "mlflow.end_run()\n",
    "\n",
    "print('\\nprocess completed')"
   ]
  },
  {
   "source": [
    "## finding the optimum batch size"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 2.2998 - binary_accuracy: 0.9001\n",
      "\n",
      "Accuracy: 0.9000972509384155\n",
      "Loss:  2.2998170852661133 \n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.2996 - binary_accuracy: 0.9001\n",
      "\n",
      "Accuracy: 0.9000972509384155\n",
      "Loss:  2.2995998859405518 \n",
      "\n",
      "313/313 [==============================] - 0s 976us/step - loss: 2.2994 - binary_accuracy: 0.9001\n",
      "\n",
      "Accuracy: 0.9001073241233826\n",
      "Loss:  2.299405336380005 \n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.2994 - binary_accuracy: 0.9001\n",
      "\n",
      "Accuracy: 0.9001073241233826\n",
      "Loss:  2.2993671894073486 \n",
      "\n",
      "313/313 [==============================] - 0s 955us/step - loss: 2.2993 - binary_accuracy: 0.9001\n",
      "\n",
      "Accuracy: 0.9001073241233826\n",
      "Loss:  2.2993459701538086 \n",
      "\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.2984 - binary_accuracy: 0.9001\n",
      "\n",
      "Accuracy: 0.9001472592353821\n",
      "Loss:  2.298449754714966 \n",
      "\n",
      "100%|██████████| 6/6 [00:59<00:00,  9.96s/it]\n",
      "process completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Starting the MLflow \n",
    "parent_run = mlflow.start_run(run_name='batch size')\n",
    "\n",
    "\n",
    "for batch_size in tqdm(np.linspace(start=50,stop=200,num=6)):\n",
    "    batch_size = int(batch_size)\n",
    "\n",
    "    with mlflow.start_run(run_name=f'bsize {batch_size}', nested=True) as child_run:\n",
    "        mlflow.set_tag(f'mlflow.note.content',f'run_id: {child_run.info.run_id}')\n",
    "\n",
    "        # model compiling\n",
    "        model.compile( optimizer = keras.optimizers.Adam(learning_rate=0.001), \n",
    "                        loss     = keras.losses.categorical_crossentropy,\n",
    "                        metrics  = [keras.metrics.binary_accuracy] )\n",
    "\n",
    "        # model optimization\n",
    "        history = model.fit(x_train, y_train, epochs=5, batch_size=batch_size, validation_data=(x_test, y_test),verbose=0)\n",
    "\n",
    "        # Model evaluation\n",
    "        test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "        print('\\nAccuracy:', test_acc) \n",
    "        print('Loss: '   , test_loss,'\\n')\n",
    "\n",
    "        prediction = model.predict(x_test)\n",
    "        predicted_classes = np.argmax(prediction, axis=1)\n",
    "\n",
    "        # Saving MLflow parameters & metrics\n",
    "        mlflow.log_param(\"epochs\",          history.params['epochs'])\n",
    "        mlflow.log_param(\"batch_size\",      batch_size)\n",
    "        mlflow.log_param(\"steps_per_epoch\", history.params['steps'])\n",
    "\n",
    "        mlflow.log_metric(\"accuracy\",       test_acc)\n",
    "        mlflow.log_metric(\"test_loss\",      test_loss)\n",
    "\n",
    "        # saving git commit hash\n",
    "        repo = git.Repo(search_parent_directories=True)\n",
    "        git_commit_hash = repo.head.object.hexsha\n",
    "        mlflow.set_tag('mlflow.source.git.commit', git_commit_hash)\n",
    "\n",
    "# ending mlflow session\n",
    "mlflow.end_run()\n",
    "\n",
    "print('\\nprocess completed')"
   ]
  },
  {
   "source": [
    "## list all runs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.list_run_infos(experiment_id='4')[0]"
   ]
  },
  {
   "source": [
    "## modify an existing run"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_id='0861236387ba4d7683e589f206dff964') as run: \n",
    "\n",
    "    mlflow.set_tag('status','final optimized learning rate')"
   ]
  },
  {
   "source": [
    "## downloading artifacts"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "client.download_artifacts(run_id='0861236387ba4d7683e589f206dff964', path='model/MLmodel', dst_path='../')"
   ]
  },
  {
   "source": [
    "## duplicate a run"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_run = mlflow.get_run(run_id='0861236387ba4d7683e589f206dff964')\n",
    "\n",
    "mlflow.create_experiment(name='new_exp', artifact_location=artifact)\n",
    "mlflow.set_experiment(experiment_name='new_exp')\n",
    "\n",
    "mlflow.log_metrics(source_run.data.metrics)\n",
    "mlflow.log_params(source_run.data.params)\n",
    "\n",
    "file_path = client.download_artifacts(run_id='0861236387ba4d7683e589f206dff964', path='', dst_path='../')\n",
    "\n",
    "\n",
    "\n",
    "mlflow.set_tag('mlflow.source.git.commit', repo.head.object.hexsha)\n",
    "mlflow.set_tag('mlflow.source.name'      , old_run.data.tags['mlflow.source.name'])\n",
    "mlflow.set_tag('mlflow.log-model.history', old_run.data.tags['mlflow.log-model.history'])\n",
    "\n",
    "\n",
    "mlflow.log_artifacts(file_path + '/model')\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "source": [
    "## loading models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_REGISTRY_NAME = 'mnist_classifier'\n",
    "\n",
    "# loading from model registry using the version of the registered model\n",
    "model = mlflow.keras.load_model(model_uri=f'models:/{MODEL_REGISTRY_NAME}/1',compile=False)\n",
    "\n",
    "# loading from model registry using the stage of the registered model\n",
    "model = mlflow.keras.load_model(model_uri=f'models:/{MODEL_REGISTRY_NAME}/production',compile=False)\n",
    "\n",
    "# loading from a specific run\n",
    "run_id = 'f7d6e3b515da4ed89578cdd53412fcf8'\n",
    "model = mlflow.keras.load_model(model_uri=f'runs:/{run_id}/model',compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimization Complete\n"
     ]
    }
   ],
   "source": [
    "# End the ssh session. If this failed, we can type 'pkill ssh' in the terminal \n",
    "ssh_session.kill()\n",
    "\n",
    "print('Optimization Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow ui --backend-store-uri postgresql://artinmajdi:1234@localhost:5000/chest_db --port 6789"
   ]
  }
 ]
}